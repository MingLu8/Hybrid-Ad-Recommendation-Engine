{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using TensorFlow version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print('Using TensorFlow version %s' % (tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../data/adult.data.csv'\n",
    "test_data_path = '../data/adult.test.csv'\n",
    "\n",
    "export_dir = 'export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "NUMERIC_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "CSV_COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(train_data_path, header=None, names=CSV_COLUMNS)\n",
    "X_test = pd.read_csv(test_data_path, header=None, names=CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: income_bracket, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "income_train = X_train[\"income_bracket\"]\n",
    "income_test = X_test[\"income_bracket\"]\n",
    "\n",
    "X_train['income_bracket'] = (X_train['income_bracket'] == ' >50K').astype(int)\n",
    "X_test['income_bracket'] = (X_test['income_bracket'] == ' >50K').astype(int)\n",
    "\n",
    "Y_train = X_train[\"income_bracket\"]\n",
    "Y_test = X_test[\"income_bracket\"]\n",
    "\n",
    "X_train = X_train.drop('fnlwgt', axis=1)\n",
    "X_test = X_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "X_train = X_train.drop('income_bracket', axis=1)\n",
    "X_test = X_test.drop('income_bracket', axis=1)\n",
    "\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Never-married', ' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='occupation', vocabulary_list=(' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners', ' Prof-specialty', ' Other-service', ' Sales', ' Craft-repair', ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct', ' Tech-support', ' ?', ' Protective-serv', ' Armed-Forces', ' Priv-house-serv'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Not-in-family', ' Husband', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='race', vocabulary_list=(' White', ' Black', ' Asian-Pac-Islander', ' Amer-Indian-Eskimo', ' Other'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Male', ' Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='native_country', vocabulary_list=(' United-States', ' Cuba', ' Jamaica', ' India', ' ?', ' Mexico', ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada', ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland', ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos', ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic', ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan', ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland', ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong', ' Ireland', ' Hungary', ' Holand-Netherlands'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "categorical_columns = []\n",
    "numeric_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = X_train[feature_name].unique()\n",
    "    col = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "    categorical_columns.append(col)\n",
    "    feature_columns.append(col)\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    col = tf.feature_column.numeric_column(feature_name, dtype=tf.float32)\n",
    "    numeric_columns.append(col)\n",
    "    feature_columns.append(col)\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_function(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_function = make_input_function(X_train, Y_train)\n",
    "eval_input_function = make_input_function(X_test, Y_test, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmplyv1puih\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmplyv1puih', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "linear_model = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:133: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmplyv1puih/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 179.628\n",
      "INFO:tensorflow:loss = 5.7943354, step = 100 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.987\n",
      "INFO:tensorflow:loss = 2.9879627, step = 200 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.271\n",
      "INFO:tensorflow:loss = 3.7592056, step = 300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.426\n",
      "INFO:tensorflow:loss = 0.54944086, step = 400 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.629\n",
      "INFO:tensorflow:loss = 8.541425, step = 500 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.904\n",
      "INFO:tensorflow:loss = 6.6914415, step = 600 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.577\n",
      "INFO:tensorflow:loss = 2.8869424, step = 700 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.356\n",
      "INFO:tensorflow:loss = 0.6167484, step = 800 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.663\n",
      "INFO:tensorflow:loss = 0.38745108, step = 900 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.864\n",
      "INFO:tensorflow:loss = 0.45407194, step = 1000 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.262\n",
      "INFO:tensorflow:loss = 0.32645616, step = 1100 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.332\n",
      "INFO:tensorflow:loss = 0.41482437, step = 1200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.342\n",
      "INFO:tensorflow:loss = 3.419092, step = 1300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.491\n",
      "INFO:tensorflow:loss = 1.0771799, step = 1400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.653\n",
      "INFO:tensorflow:loss = 0.6062427, step = 1500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.991\n",
      "INFO:tensorflow:loss = 3.6751757, step = 1600 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.519\n",
      "INFO:tensorflow:loss = 2.5305073, step = 1700 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.733\n",
      "INFO:tensorflow:loss = 1.5128691, step = 1800 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.602\n",
      "INFO:tensorflow:loss = 0.42425686, step = 1900 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.916\n",
      "INFO:tensorflow:loss = 1.5714839, step = 2000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.711\n",
      "INFO:tensorflow:loss = 4.648894, step = 2100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.249\n",
      "INFO:tensorflow:loss = 1.5811601, step = 2200 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.822\n",
      "INFO:tensorflow:loss = 0.22705263, step = 2300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.905\n",
      "INFO:tensorflow:loss = 0.5808003, step = 2400 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.021\n",
      "INFO:tensorflow:loss = 0.3442457, step = 2500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.98\n",
      "INFO:tensorflow:loss = 0.25911885, step = 2600 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.833\n",
      "INFO:tensorflow:loss = 0.6516429, step = 2700 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.086\n",
      "INFO:tensorflow:loss = 2.2432275, step = 2800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.035\n",
      "INFO:tensorflow:loss = 0.33543956, step = 2900 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.479\n",
      "INFO:tensorflow:loss = 0.68696976, step = 3000 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.429\n",
      "INFO:tensorflow:loss = 6.018568, step = 3100 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.316\n",
      "INFO:tensorflow:loss = 0.8252436, step = 3200 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.017\n",
      "INFO:tensorflow:loss = 0.29857892, step = 3300 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.622\n",
      "INFO:tensorflow:loss = 7.723257, step = 3400 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.424\n",
      "INFO:tensorflow:loss = 2.4472399, step = 3500 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.432\n",
      "INFO:tensorflow:loss = 0.40587437, step = 3600 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.115\n",
      "INFO:tensorflow:loss = 0.5660542, step = 3700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.148\n",
      "INFO:tensorflow:loss = 1.0674231, step = 3800 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.963\n",
      "INFO:tensorflow:loss = 0.47772145, step = 3900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.679\n",
      "INFO:tensorflow:loss = 0.33062965, step = 4000 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.91\n",
      "INFO:tensorflow:loss = 0.36740467, step = 4100 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.667\n",
      "INFO:tensorflow:loss = 0.34076914, step = 4200 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.001\n",
      "INFO:tensorflow:loss = 1.1547599, step = 4300 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.276\n",
      "INFO:tensorflow:loss = 1.1743896, step = 4400 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.904\n",
      "INFO:tensorflow:loss = 0.32865766, step = 4500 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.777\n",
      "INFO:tensorflow:loss = 0.5312549, step = 4600 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.565\n",
      "INFO:tensorflow:loss = 0.31935114, step = 4700 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.108\n",
      "INFO:tensorflow:loss = 0.8640605, step = 4800 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.984\n",
      "INFO:tensorflow:loss = 0.3143468, step = 4900 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.417\n",
      "INFO:tensorflow:loss = 0.26328355, step = 5000 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.322\n",
      "INFO:tensorflow:loss = 0.49900854, step = 5100 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.902\n",
      "INFO:tensorflow:loss = 0.66369, step = 5200 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.743\n",
      "INFO:tensorflow:loss = 0.39008164, step = 5300 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.114\n",
      "INFO:tensorflow:loss = 0.5093193, step = 5400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.096\n",
      "INFO:tensorflow:loss = 0.4471991, step = 5500 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.377\n",
      "INFO:tensorflow:loss = 0.40780333, step = 5600 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.543\n",
      "INFO:tensorflow:loss = 1.5008483, step = 5700 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.893\n",
      "INFO:tensorflow:loss = 2.6056118, step = 5800 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.837\n",
      "INFO:tensorflow:loss = 4.34649, step = 5900 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.419\n",
      "INFO:tensorflow:loss = 0.38124394, step = 6000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.503\n",
      "INFO:tensorflow:loss = 2.5239713, step = 6100 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 353\n",
      "INFO:tensorflow:loss = 0.46500307, step = 6200 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.323\n",
      "INFO:tensorflow:loss = 0.89816123, step = 6300 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.662\n",
      "INFO:tensorflow:loss = 3.5487428, step = 6400 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.257\n",
      "INFO:tensorflow:loss = 0.3053628, step = 6500 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.051\n",
      "INFO:tensorflow:loss = 0.4729396, step = 6600 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.669\n",
      "INFO:tensorflow:loss = 0.2932605, step = 6700 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.337\n",
      "INFO:tensorflow:loss = 0.10979106, step = 6800 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.597\n",
      "INFO:tensorflow:loss = 0.28493714, step = 6900 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.711\n",
      "INFO:tensorflow:loss = 0.69405884, step = 7000 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.71\n",
      "INFO:tensorflow:loss = 0.20236196, step = 7100 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.149\n",
      "INFO:tensorflow:loss = 0.4991261, step = 7200 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.879\n",
      "INFO:tensorflow:loss = 0.38525307, step = 7300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.943\n",
      "INFO:tensorflow:loss = 3.4857142, step = 7400 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.678\n",
      "INFO:tensorflow:loss = 0.31037158, step = 7500 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.932\n",
      "INFO:tensorflow:loss = 0.23514359, step = 7600 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.77\n",
      "INFO:tensorflow:loss = 0.2758923, step = 7700 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.756\n",
      "INFO:tensorflow:loss = 1.1109757, step = 7800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.442\n",
      "INFO:tensorflow:loss = 0.4245907, step = 7900 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.388\n",
      "INFO:tensorflow:loss = 0.5331154, step = 8000 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.522\n",
      "INFO:tensorflow:loss = 0.591091, step = 8100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.665\n",
      "INFO:tensorflow:loss = 1.5496322, step = 8200 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.109\n",
      "INFO:tensorflow:loss = 0.5460148, step = 8300 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.892\n",
      "INFO:tensorflow:loss = 1.8720379, step = 8400 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.76\n",
      "INFO:tensorflow:loss = 0.30942553, step = 8500 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.48\n",
      "INFO:tensorflow:loss = 0.37524796, step = 8600 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.693\n",
      "INFO:tensorflow:loss = 0.19018605, step = 8700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.557\n",
      "INFO:tensorflow:loss = 0.3570438, step = 8800 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.451\n",
      "INFO:tensorflow:loss = 0.30244306, step = 8900 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.684\n",
      "INFO:tensorflow:loss = 0.2644498, step = 9000 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.608\n",
      "INFO:tensorflow:loss = 0.37885413, step = 9100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.91\n",
      "INFO:tensorflow:loss = 0.43213814, step = 9200 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.326\n",
      "INFO:tensorflow:loss = 0.45572612, step = 9300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.348\n",
      "INFO:tensorflow:loss = 0.2337536, step = 9400 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.709\n",
      "INFO:tensorflow:loss = 0.4911446, step = 9500 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.536\n",
      "INFO:tensorflow:loss = 5.3294916, step = 9600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.697\n",
      "INFO:tensorflow:loss = 1.2196586, step = 9700 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.089\n",
      "INFO:tensorflow:loss = 0.47571325, step = 9800 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.22\n",
      "INFO:tensorflow:loss = 0.093165174, step = 9900 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.326\n",
      "INFO:tensorflow:loss = 4.3147736, step = 10000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.689\n",
      "INFO:tensorflow:loss = 0.45662254, step = 10100 (0.290 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10180...\n",
      "INFO:tensorflow:Saving checkpoints for 10180 into /tmp/tmplyv1puih/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10180...\n",
      "INFO:tensorflow:Loss for final step: 0.32496423.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-05T02:28:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplyv1puih/model.ckpt-10180\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.44862s\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-05-02:28:58\n",
      "INFO:tensorflow:Saving dict for global step 10180: accuracy = 0.8470328, accuracy_baseline = 0.7637916, auc = 0.9003508, auc_precision_recall = 0.75215906, average_loss = 0.341367, global_step = 10180, label/mean = 0.23620838, loss = 0.34122118, precision = 0.7491725, prediction/mean = 0.20046398, recall = 0.52977896\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10180: /tmp/tmplyv1puih/model.ckpt-10180\n"
     ]
    }
   ],
   "source": [
    "linear_model.train(train_input_function)\n",
    "result = linear_model.evaluate(eval_input_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8470328\n"
     ]
    }
   ],
   "source": [
    "print(result['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_input_function(features, batch_size = 256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpviv3z1d1/model.ckpt-10180\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \">50K\" (100.0%), Real value: \" >50K\"\"\n"
     ]
    }
   ],
   "source": [
    "income_type = ['<=50K', '>50K']\n",
    "i = 3\n",
    "newX = X_test.iloc[i:i+1]\n",
    "newY = income_test[i]\n",
    "predictions = linear_model.predict(input_fn = lambda: prediction_input_function(newX))\n",
    "\n",
    "for pred_dict in predictions: \n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]    \n",
    "    print('Prediction is \"{}\" ({:.1f}%), Real value: \"{}\"\"'.format(income_type[class_id], 100 * probability, newY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpviv3z1d1/model.ckpt-10180\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export/temp-1609809296/saved_model.pb\n",
      "model dir: b'export/1609809296'\n"
     ]
    }
   ],
   "source": [
    "feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n",
    "\n",
    "# Build receiver function, and export.\n",
    "serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "model_dir = linear_model.export_saved_model(export_dir, serving_input_receiver_fn)\n",
    "print('model dir:', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(i):\n",
    "    inputs = X_test[i:i+1]\n",
    "    example = tf.train.Example()\n",
    "    for col in inputs:  \n",
    "        if col in CATEGORICAL_COLUMNS:  \n",
    "            cat_value = inputs[col].tolist()[0][0].encode('utf8')\n",
    "            example.features.feature[col].bytes_list.value.extend([cat_value]) \n",
    "        if col in NUMERIC_COLUMNS:\n",
    "            example.features.feature[col].float_list.value.extend(inputs[col])\n",
    "    return imported.signatures[\"predict\"](examples=tf.constant([example.SerializeToString()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = predict(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction is \">50K\" (100.0%)\n"
     ]
    }
   ],
   "source": [
    "class_ids = predictions['class_ids'].numpy()[0][0]\n",
    "probability = predictions['probabilities'].numpy()[0][class_ids]\n",
    "print('Prediction is \"{}\" ({:.1f}%)'.format(income_type[class_ids], 100 * probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}