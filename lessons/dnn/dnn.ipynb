{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using TensorFlow version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print('Using TensorFlow version %s' % (tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../data/adult.data.csv'\n",
    "test_data_path = '../data/adult.test.csv'\n",
    "\n",
    "export_dir = 'export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "NUMERIC_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "CSV_COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(train_data_path, header=None, names=CSV_COLUMNS)\n",
    "X_test = pd.read_csv(test_data_path, header=None, names=CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: income_bracket, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "income_train = X_train[\"income_bracket\"]\n",
    "income_test = X_test[\"income_bracket\"]\n",
    "\n",
    "X_train['income_bracket'] = (X_train['income_bracket'] == ' >50K').astype(int)\n",
    "X_test['income_bracket'] = (X_test['income_bracket'] == ' >50K').astype(int)\n",
    "\n",
    "Y_train = X_train[\"income_bracket\"]\n",
    "Y_test = X_test[\"income_bracket\"]\n",
    "\n",
    "X_train = X_train.drop('fnlwgt', axis=1)\n",
    "X_test = X_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "X_train = X_train.drop('income_bracket', axis=1)\n",
    "X_test = X_test.drop('income_bracket', axis=1)\n",
    "\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Never-married', ' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='occupation', vocabulary_list=(' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners', ' Prof-specialty', ' Other-service', ' Sales', ' Craft-repair', ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct', ' Tech-support', ' ?', ' Protective-serv', ' Armed-Forces', ' Priv-house-serv'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Not-in-family', ' Husband', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='race', vocabulary_list=(' White', ' Black', ' Asian-Pac-Islander', ' Amer-Indian-Eskimo', ' Other'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Male', ' Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='native_country', vocabulary_list=(' United-States', ' Cuba', ' Jamaica', ' India', ' ?', ' Mexico', ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada', ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland', ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos', ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic', ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan', ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland', ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong', ' Ireland', ' Hungary', ' Holand-Netherlands'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "categorical_columns = []\n",
    "numeric_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = X_train[feature_name].unique()\n",
    "    col = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "    categorical_columns.append(col)\n",
    "    feature_columns.append(col)\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    col = tf.feature_column.numeric_column(feature_name, dtype=tf.float32)\n",
    "    numeric_columns.append(col)\n",
    "    feature_columns.append(col)\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_function(features, labels, training=True, batch_size = 256):\n",
    "    def input_function():        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "        if training:\n",
    "            dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "        return dataset.batch(batch_size)\n",
    "\n",
    "    return input_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_function = make_input_function(X_train, Y_train)\n",
    "eval_input_function = make_input_function(X_test, Y_test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzf_2sf45\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpzf_2sf45', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "deep_columns = []\n",
    "for col in categorical_columns:\n",
    "    deep_columns.append(tf.feature_column.indicator_column(col))\n",
    "\n",
    "for col in numeric_columns:\n",
    "    deep_columns.append(col)\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=deep_columns,\n",
    "    hidden_units = [30, 10],\n",
    "    n_classes=2\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpzf_2sf45/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 11.742542, step = 0\n",
      "INFO:tensorflow:global_step/sec: 189.873\n",
      "INFO:tensorflow:loss = 0.566441, step = 100 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.005\n",
      "INFO:tensorflow:loss = 0.47907874, step = 200 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.607\n",
      "INFO:tensorflow:loss = 0.46038243, step = 300 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.513\n",
      "INFO:tensorflow:loss = 0.5277344, step = 400 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.97\n",
      "INFO:tensorflow:loss = 0.4818145, step = 500 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.697\n",
      "INFO:tensorflow:loss = 0.5597988, step = 600 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.854\n",
      "INFO:tensorflow:loss = 0.6016544, step = 700 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.542\n",
      "INFO:tensorflow:loss = 0.46424812, step = 800 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.528\n",
      "INFO:tensorflow:loss = 0.4561273, step = 900 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.049\n",
      "INFO:tensorflow:loss = 0.5305053, step = 1000 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.11\n",
      "INFO:tensorflow:loss = 0.5346045, step = 1100 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.201\n",
      "INFO:tensorflow:loss = 0.4305616, step = 1200 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.338\n",
      "INFO:tensorflow:loss = 0.48044336, step = 1300 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.813\n",
      "INFO:tensorflow:loss = 0.63608116, step = 1400 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.247\n",
      "INFO:tensorflow:loss = 0.5652003, step = 1500 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.186\n",
      "INFO:tensorflow:loss = 0.40476698, step = 1600 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.386\n",
      "INFO:tensorflow:loss = 0.44223303, step = 1700 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.376\n",
      "INFO:tensorflow:loss = 0.43164012, step = 1800 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.331\n",
      "INFO:tensorflow:loss = 0.5339161, step = 1900 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.77\n",
      "INFO:tensorflow:loss = 0.4494638, step = 2000 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.501\n",
      "INFO:tensorflow:loss = 0.49463624, step = 2100 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.521\n",
      "INFO:tensorflow:loss = 0.47317818, step = 2200 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.407\n",
      "INFO:tensorflow:loss = 0.48970145, step = 2300 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.853\n",
      "INFO:tensorflow:loss = 0.47724658, step = 2400 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.025\n",
      "INFO:tensorflow:loss = 0.4968512, step = 2500 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.366\n",
      "INFO:tensorflow:loss = 0.4548775, step = 2600 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.741\n",
      "INFO:tensorflow:loss = 0.4724011, step = 2700 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.288\n",
      "INFO:tensorflow:loss = 0.44977903, step = 2800 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.29\n",
      "INFO:tensorflow:loss = 0.47833702, step = 2900 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.899\n",
      "INFO:tensorflow:loss = 0.54126644, step = 3000 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.301\n",
      "INFO:tensorflow:loss = 0.48132133, step = 3100 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.869\n",
      "INFO:tensorflow:loss = 0.53162694, step = 3200 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.094\n",
      "INFO:tensorflow:loss = 0.45888025, step = 3300 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.421\n",
      "INFO:tensorflow:loss = 0.41110817, step = 3400 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.016\n",
      "INFO:tensorflow:loss = 0.3984986, step = 3500 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.489\n",
      "INFO:tensorflow:loss = 0.404294, step = 3600 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.648\n",
      "INFO:tensorflow:loss = 0.43628067, step = 3700 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.218\n",
      "INFO:tensorflow:loss = 0.44025365, step = 3800 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.946\n",
      "INFO:tensorflow:loss = 0.45091432, step = 3900 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.785\n",
      "INFO:tensorflow:loss = 0.42265332, step = 4000 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.382\n",
      "INFO:tensorflow:loss = 0.36538827, step = 4100 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.41\n",
      "INFO:tensorflow:loss = 0.4668923, step = 4200 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.683\n",
      "INFO:tensorflow:loss = 0.45651123, step = 4300 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.679\n",
      "INFO:tensorflow:loss = 0.42588294, step = 4400 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.01\n",
      "INFO:tensorflow:loss = 0.41945425, step = 4500 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.707\n",
      "INFO:tensorflow:loss = 0.42666364, step = 4600 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.893\n",
      "INFO:tensorflow:loss = 0.4039181, step = 4700 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.138\n",
      "INFO:tensorflow:loss = 0.38567758, step = 4800 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.904\n",
      "INFO:tensorflow:loss = 0.38868153, step = 4900 (0.429 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpzf_2sf45/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.36170012.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f7c0802e4c0>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "classifier.train(input_fn = make_input_function(X_train, Y_train, training=True), steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-05T01:50:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzf_2sf45/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.06802s\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-05-01:50:34\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8056272, accuracy_baseline = 0.7637916, auc = 0.8238, auc_precision_recall = 0.6379304, average_loss = 0.4244011, global_step = 5000, label/mean = 0.23620838, loss = 0.42447194, precision = 0.7241606, prediction/mean = 0.2587335, recall = 0.2860858\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpzf_2sf45/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "result = classifier.evaluate(input_fn=make_input_function(X_test, Y_test, training=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.806\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {accuracy:0.3f}\\n\".format(**result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_input_function(features, batch_size = 256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzf_2sf45/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \">50K\" (99.9%), Real value: \" >50K\"\"\n"
     ]
    }
   ],
   "source": [
    "income_type = ['<=50K', '>50K']\n",
    "\n",
    "i = 53\n",
    "newX = X_test.iloc[i:i+1]\n",
    "newY = income_test[i]\n",
    "predictions = classifier.predict(input_fn = lambda: prediction_input_function(newX))\n",
    "\n",
    "for pred_dict in predictions: \n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]   \n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), Real value: \"{}\"\"'.format(income_type[class_id], 100 * probability, newY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzf_2sf45/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export/temp-1609811435/saved_model.pb\n",
      "model dir: b'export/1609811435'\n"
     ]
    }
   ],
   "source": [
    "feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n",
    "\n",
    "# Build receiver function, and export.\n",
    "serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "model_dir = classifier.export_saved_model(export_dir, serving_input_receiver_fn)\n",
    "print('model dir:', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(i):\n",
    "    inputs = X_test[i:i+1]\n",
    "    example = tf.train.Example()\n",
    "    for col in inputs:  \n",
    "        if col in CATEGORICAL_COLUMNS:  \n",
    "            cat_value = inputs[col].tolist()[0][0].encode('utf8')\n",
    "            example.features.feature[col].bytes_list.value.extend([cat_value]) \n",
    "        if col in NUMERIC_COLUMNS:\n",
    "            example.features.feature[col].float_list.value.extend(inputs[col])\n",
    "    return imported.signatures[\"predict\"](examples=tf.constant([example.SerializeToString()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction is \">50K\" (93.9%)\n"
     ]
    }
   ],
   "source": [
    "class_ids = predictions['class_ids'].numpy()[0][0]\n",
    "probability = predictions['probabilities'].numpy()[0][class_ids]\n",
    "print('Prediction is \"{}\" ({:.1f}%)'.format(income_type[class_ids], 100 * probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}